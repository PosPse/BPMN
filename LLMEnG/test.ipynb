{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
     ]
    }
   ],
   "source": [
    "dataset_cora = Planetoid(root='./cora/', name='Cora')\n",
    "# dataset = Planetoid(root='./citeseer',name='Citeseer')\n",
    "# dataset = Planetoid(root='./pubmed/',name='Pubmed')\n",
    "print(dataset_cora[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/btr/miniconda3/envs/LLMEnG/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 4.1851, -0.2059, -1.8382,  ..., -2.8908,  1.3605,  0.3109],\n",
      "         [-1.8622, -0.9529, -2.4024,  ...,  1.0467,  1.3186,  1.0996],\n",
      "         [-0.2761, -0.4898, -0.9106,  ...,  1.2816,  0.6039,  1.7683],\n",
      "         ...,\n",
      "         [-0.3205, -2.7684, -2.1332,  ...,  1.1992,  0.9619,  1.0644],\n",
      "         [ 2.1264, -4.0235, -3.8833,  ..., -1.4924,  1.3204,  1.5962],\n",
      "         [-2.7754, -2.8158, -1.3051,  ..., -1.8278, -0.0244,  1.6202]]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# 定义模型和tokenizer的本地路径\n",
    "local_model_path = \"/home/btr/bpmn/model/safetensors/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "# 加载预训练的tokenizer和模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
    "model = AutoModel.from_pretrained(local_model_path)\n",
    "\n",
    "# 要处理的输入文本\n",
    "text = \"这是一个示例文本\"\n",
    "\n",
    "# 将文本转换为tokenizer的输入格式\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# 获取模型的最后一层隐藏状态作为嵌入表示\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# 获取最后一层隐藏状态\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "# 输出嵌入表示\n",
    "print(last_hidden_states)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 4096])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.nn import GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = SAGEConv(dataset_cora.num_node_features, 16, 'lstm')\n",
    "        self.conv2 = SAGEConv(16, dataset_cora.num_classes, 'lstm')\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class GAT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(dataset_cora.num_node_features, 16, heads=2)\n",
    "        self.conv2 = GATConv(2*16, dataset_cora.num_classes, heads=1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.softmax(x, dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT(\n",
      "  (conv1): GATConv(1433, 16, heads=2)\n",
      "  (conv2): GATConv(32, 7, heads=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GAT()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model.to(device)\n",
    "data = dataset_cora[0].to(device)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 train_loss: 1.9451 train_acc: 0.1857\n",
      "Epoch 001 train_loss: 1.9166 train_acc: 0.7214\n",
      "Epoch 002 train_loss: 1.8723 train_acc: 0.8071\n",
      "Epoch 003 train_loss: 1.8173 train_acc: 0.7786\n",
      "Epoch 004 train_loss: 1.7426 train_acc: 0.8000\n",
      "Epoch 005 train_loss: 1.6530 train_acc: 0.8929\n",
      "Epoch 006 train_loss: 1.5969 train_acc: 0.8714\n",
      "Epoch 007 train_loss: 1.5263 train_acc: 0.8571\n",
      "Epoch 008 train_loss: 1.4645 train_acc: 0.9143\n",
      "Epoch 009 train_loss: 1.4076 train_acc: 0.9500\n",
      "Epoch 010 train_loss: 1.3652 train_acc: 0.9429\n",
      "Epoch 011 train_loss: 1.3142 train_acc: 0.9714\n",
      "Epoch 012 train_loss: 1.2917 train_acc: 0.9571\n",
      "Epoch 013 train_loss: 1.2634 train_acc: 0.9714\n",
      "Epoch 014 train_loss: 1.2558 train_acc: 0.9714\n",
      "Epoch 015 train_loss: 1.2349 train_acc: 0.9857\n",
      "Epoch 016 train_loss: 1.2239 train_acc: 0.9786\n",
      "Epoch 017 train_loss: 1.2058 train_acc: 0.9857\n",
      "Epoch 018 train_loss: 1.2125 train_acc: 0.9714\n",
      "Epoch 019 train_loss: 1.2058 train_acc: 0.9786\n",
      "Epoch 020 train_loss: 1.1977 train_acc: 0.9786\n",
      "Epoch 021 train_loss: 1.1884 train_acc: 0.9929\n",
      "Epoch 022 train_loss: 1.1893 train_acc: 0.9857\n",
      "Epoch 023 train_loss: 1.1907 train_acc: 0.9857\n",
      "Epoch 024 train_loss: 1.1900 train_acc: 1.0000\n",
      "Epoch 025 train_loss: 1.1811 train_acc: 1.0000\n",
      "Epoch 026 train_loss: 1.1859 train_acc: 0.9857\n",
      "Epoch 027 train_loss: 1.1821 train_acc: 1.0000\n",
      "Epoch 028 train_loss: 1.1839 train_acc: 0.9929\n",
      "Epoch 029 train_loss: 1.1748 train_acc: 1.0000\n",
      "Epoch 030 train_loss: 1.1736 train_acc: 1.0000\n",
      "Epoch 031 train_loss: 1.1713 train_acc: 1.0000\n",
      "Epoch 032 train_loss: 1.1728 train_acc: 1.0000\n",
      "Epoch 033 train_loss: 1.1739 train_acc: 1.0000\n",
      "Epoch 034 train_loss: 1.1732 train_acc: 1.0000\n",
      "Epoch 035 train_loss: 1.1853 train_acc: 0.9929\n",
      "Epoch 036 train_loss: 1.1770 train_acc: 1.0000\n",
      "Epoch 037 train_loss: 1.1768 train_acc: 1.0000\n",
      "Epoch 038 train_loss: 1.1710 train_acc: 1.0000\n",
      "Epoch 039 train_loss: 1.1715 train_acc: 1.0000\n",
      "Epoch 040 train_loss: 1.1840 train_acc: 0.9929\n",
      "Epoch 041 train_loss: 1.1820 train_acc: 0.9929\n",
      "Epoch 042 train_loss: 1.1725 train_acc: 1.0000\n",
      "Epoch 043 train_loss: 1.1758 train_acc: 1.0000\n",
      "Epoch 044 train_loss: 1.1800 train_acc: 1.0000\n",
      "Epoch 045 train_loss: 1.1788 train_acc: 0.9929\n",
      "Epoch 046 train_loss: 1.1782 train_acc: 1.0000\n",
      "Epoch 047 train_loss: 1.1720 train_acc: 1.0000\n",
      "Epoch 048 train_loss: 1.1803 train_acc: 0.9929\n",
      "Epoch 049 train_loss: 1.1717 train_acc: 1.0000\n",
      "Epoch 050 train_loss: 1.1826 train_acc: 0.9929\n",
      "Epoch 051 train_loss: 1.1745 train_acc: 1.0000\n",
      "Epoch 052 train_loss: 1.1785 train_acc: 1.0000\n",
      "Epoch 053 train_loss: 1.1785 train_acc: 1.0000\n",
      "Epoch 054 train_loss: 1.1816 train_acc: 0.9929\n",
      "Epoch 055 train_loss: 1.1840 train_acc: 0.9929\n",
      "Epoch 056 train_loss: 1.1741 train_acc: 1.0000\n",
      "Epoch 057 train_loss: 1.1791 train_acc: 1.0000\n",
      "Epoch 058 train_loss: 1.1757 train_acc: 1.0000\n",
      "Epoch 059 train_loss: 1.1884 train_acc: 0.9857\n",
      "Epoch 060 train_loss: 1.1815 train_acc: 0.9929\n",
      "Epoch 061 train_loss: 1.1800 train_acc: 1.0000\n",
      "Epoch 062 train_loss: 1.1761 train_acc: 1.0000\n",
      "Epoch 063 train_loss: 1.1777 train_acc: 1.0000\n",
      "Epoch 064 train_loss: 1.1719 train_acc: 1.0000\n",
      "Epoch 065 train_loss: 1.1730 train_acc: 1.0000\n",
      "Epoch 066 train_loss: 1.1729 train_acc: 1.0000\n",
      "Epoch 067 train_loss: 1.1745 train_acc: 1.0000\n",
      "Epoch 068 train_loss: 1.1771 train_acc: 1.0000\n",
      "Epoch 069 train_loss: 1.1738 train_acc: 1.0000\n",
      "Epoch 070 train_loss: 1.1792 train_acc: 1.0000\n",
      "Epoch 071 train_loss: 1.1777 train_acc: 1.0000\n",
      "Epoch 072 train_loss: 1.1786 train_acc: 0.9929\n",
      "Epoch 073 train_loss: 1.1709 train_acc: 1.0000\n",
      "Epoch 074 train_loss: 1.1735 train_acc: 1.0000\n",
      "Epoch 075 train_loss: 1.1741 train_acc: 1.0000\n",
      "Epoch 076 train_loss: 1.1770 train_acc: 0.9929\n",
      "Epoch 077 train_loss: 1.1736 train_acc: 1.0000\n",
      "Epoch 078 train_loss: 1.1723 train_acc: 1.0000\n",
      "Epoch 079 train_loss: 1.1742 train_acc: 1.0000\n",
      "Epoch 080 train_loss: 1.1764 train_acc: 1.0000\n",
      "Epoch 081 train_loss: 1.1761 train_acc: 1.0000\n",
      "Epoch 082 train_loss: 1.1752 train_acc: 1.0000\n",
      "Epoch 083 train_loss: 1.1719 train_acc: 1.0000\n",
      "Epoch 084 train_loss: 1.1732 train_acc: 1.0000\n",
      "Epoch 085 train_loss: 1.1749 train_acc: 1.0000\n",
      "Epoch 086 train_loss: 1.1739 train_acc: 1.0000\n",
      "Epoch 087 train_loss: 1.1747 train_acc: 1.0000\n",
      "Epoch 088 train_loss: 1.1749 train_acc: 1.0000\n",
      "Epoch 089 train_loss: 1.1788 train_acc: 1.0000\n",
      "Epoch 090 train_loss: 1.1721 train_acc: 1.0000\n",
      "Epoch 091 train_loss: 1.1735 train_acc: 1.0000\n",
      "Epoch 092 train_loss: 1.1762 train_acc: 1.0000\n",
      "Epoch 093 train_loss: 1.1744 train_acc: 1.0000\n",
      "Epoch 094 train_loss: 1.1723 train_acc: 1.0000\n",
      "Epoch 095 train_loss: 1.1758 train_acc: 1.0000\n",
      "Epoch 096 train_loss: 1.1727 train_acc: 1.0000\n",
      "Epoch 097 train_loss: 1.1761 train_acc: 1.0000\n",
      "Epoch 098 train_loss: 1.1703 train_acc: 1.0000\n",
      "Epoch 099 train_loss: 1.1745 train_acc: 1.0000\n",
      "Epoch 100 train_loss: 1.1713 train_acc: 1.0000\n",
      "Epoch 101 train_loss: 1.1695 train_acc: 1.0000\n",
      "Epoch 102 train_loss: 1.1723 train_acc: 1.0000\n",
      "Epoch 103 train_loss: 1.1772 train_acc: 0.9929\n",
      "Epoch 104 train_loss: 1.1727 train_acc: 1.0000\n",
      "Epoch 105 train_loss: 1.1726 train_acc: 1.0000\n",
      "Epoch 106 train_loss: 1.1706 train_acc: 1.0000\n",
      "Epoch 107 train_loss: 1.1711 train_acc: 1.0000\n",
      "Epoch 108 train_loss: 1.1722 train_acc: 1.0000\n",
      "Epoch 109 train_loss: 1.1709 train_acc: 1.0000\n",
      "Epoch 110 train_loss: 1.1770 train_acc: 1.0000\n",
      "Epoch 111 train_loss: 1.1759 train_acc: 1.0000\n",
      "Epoch 112 train_loss: 1.1726 train_acc: 1.0000\n",
      "Epoch 113 train_loss: 1.1834 train_acc: 0.9857\n",
      "Epoch 114 train_loss: 1.1763 train_acc: 0.9929\n",
      "Epoch 115 train_loss: 1.1716 train_acc: 1.0000\n",
      "Epoch 116 train_loss: 1.1726 train_acc: 1.0000\n",
      "Epoch 117 train_loss: 1.1727 train_acc: 1.0000\n",
      "Epoch 118 train_loss: 1.1716 train_acc: 1.0000\n",
      "Epoch 119 train_loss: 1.1729 train_acc: 1.0000\n",
      "Epoch 120 train_loss: 1.1768 train_acc: 0.9929\n",
      "Epoch 121 train_loss: 1.1735 train_acc: 1.0000\n",
      "Epoch 122 train_loss: 1.1736 train_acc: 1.0000\n",
      "Epoch 123 train_loss: 1.1730 train_acc: 1.0000\n",
      "Epoch 124 train_loss: 1.1767 train_acc: 1.0000\n",
      "Epoch 125 train_loss: 1.1722 train_acc: 1.0000\n",
      "Epoch 126 train_loss: 1.1763 train_acc: 0.9929\n",
      "Epoch 127 train_loss: 1.1722 train_acc: 1.0000\n",
      "Epoch 128 train_loss: 1.1725 train_acc: 1.0000\n",
      "Epoch 129 train_loss: 1.1700 train_acc: 1.0000\n",
      "Epoch 130 train_loss: 1.1707 train_acc: 1.0000\n",
      "Epoch 131 train_loss: 1.1717 train_acc: 1.0000\n",
      "Epoch 132 train_loss: 1.1709 train_acc: 1.0000\n",
      "Epoch 133 train_loss: 1.1737 train_acc: 1.0000\n",
      "Epoch 134 train_loss: 1.1750 train_acc: 1.0000\n",
      "Epoch 135 train_loss: 1.1704 train_acc: 1.0000\n",
      "Epoch 136 train_loss: 1.1737 train_acc: 1.0000\n",
      "Epoch 137 train_loss: 1.1719 train_acc: 1.0000\n",
      "Epoch 138 train_loss: 1.1730 train_acc: 1.0000\n",
      "Epoch 139 train_loss: 1.1761 train_acc: 0.9929\n",
      "Epoch 140 train_loss: 1.1729 train_acc: 1.0000\n",
      "Epoch 141 train_loss: 1.1736 train_acc: 1.0000\n",
      "Epoch 142 train_loss: 1.1735 train_acc: 1.0000\n",
      "Epoch 143 train_loss: 1.1729 train_acc: 1.0000\n",
      "Epoch 144 train_loss: 1.1708 train_acc: 1.0000\n",
      "Epoch 145 train_loss: 1.1756 train_acc: 1.0000\n",
      "Epoch 146 train_loss: 1.1736 train_acc: 1.0000\n",
      "Epoch 147 train_loss: 1.1747 train_acc: 1.0000\n",
      "Epoch 148 train_loss: 1.1740 train_acc: 1.0000\n",
      "Epoch 149 train_loss: 1.1738 train_acc: 1.0000\n",
      "Epoch 150 train_loss: 1.1757 train_acc: 1.0000\n",
      "Epoch 151 train_loss: 1.1730 train_acc: 1.0000\n",
      "Epoch 152 train_loss: 1.1718 train_acc: 1.0000\n",
      "Epoch 153 train_loss: 1.1706 train_acc: 1.0000\n",
      "Epoch 154 train_loss: 1.1779 train_acc: 0.9929\n",
      "Epoch 155 train_loss: 1.1721 train_acc: 1.0000\n",
      "Epoch 156 train_loss: 1.1733 train_acc: 1.0000\n",
      "Epoch 157 train_loss: 1.1703 train_acc: 1.0000\n",
      "Epoch 158 train_loss: 1.1733 train_acc: 1.0000\n",
      "Epoch 159 train_loss: 1.1735 train_acc: 1.0000\n",
      "Epoch 160 train_loss: 1.1723 train_acc: 1.0000\n",
      "Epoch 161 train_loss: 1.1751 train_acc: 0.9929\n",
      "Epoch 162 train_loss: 1.1718 train_acc: 1.0000\n",
      "Epoch 163 train_loss: 1.1706 train_acc: 1.0000\n",
      "Epoch 164 train_loss: 1.1745 train_acc: 1.0000\n",
      "Epoch 165 train_loss: 1.1778 train_acc: 0.9929\n",
      "Epoch 166 train_loss: 1.1722 train_acc: 1.0000\n",
      "Epoch 167 train_loss: 1.1759 train_acc: 1.0000\n",
      "Epoch 168 train_loss: 1.1724 train_acc: 1.0000\n",
      "Epoch 169 train_loss: 1.1698 train_acc: 1.0000\n",
      "Epoch 170 train_loss: 1.1727 train_acc: 1.0000\n",
      "Epoch 171 train_loss: 1.1780 train_acc: 1.0000\n",
      "Epoch 172 train_loss: 1.1750 train_acc: 1.0000\n",
      "Epoch 173 train_loss: 1.1799 train_acc: 0.9929\n",
      "Epoch 174 train_loss: 1.1741 train_acc: 1.0000\n",
      "Epoch 175 train_loss: 1.1739 train_acc: 1.0000\n",
      "Epoch 176 train_loss: 1.1768 train_acc: 0.9929\n",
      "Epoch 177 train_loss: 1.1718 train_acc: 1.0000\n",
      "Epoch 178 train_loss: 1.1708 train_acc: 1.0000\n",
      "Epoch 179 train_loss: 1.1716 train_acc: 1.0000\n",
      "Epoch 180 train_loss: 1.1761 train_acc: 0.9929\n",
      "Epoch 181 train_loss: 1.1712 train_acc: 1.0000\n",
      "Epoch 182 train_loss: 1.1707 train_acc: 1.0000\n",
      "Epoch 183 train_loss: 1.1707 train_acc: 1.0000\n",
      "Epoch 184 train_loss: 1.1703 train_acc: 1.0000\n",
      "Epoch 185 train_loss: 1.1801 train_acc: 0.9929\n",
      "Epoch 186 train_loss: 1.1738 train_acc: 1.0000\n",
      "Epoch 187 train_loss: 1.1747 train_acc: 0.9929\n",
      "Epoch 188 train_loss: 1.1715 train_acc: 1.0000\n",
      "Epoch 189 train_loss: 1.1717 train_acc: 1.0000\n",
      "Epoch 190 train_loss: 1.1730 train_acc: 1.0000\n",
      "Epoch 191 train_loss: 1.1743 train_acc: 1.0000\n",
      "Epoch 192 train_loss: 1.1718 train_acc: 1.0000\n",
      "Epoch 193 train_loss: 1.1767 train_acc: 0.9929\n",
      "Epoch 194 train_loss: 1.1723 train_acc: 1.0000\n",
      "Epoch 195 train_loss: 1.1725 train_acc: 1.0000\n",
      "Epoch 196 train_loss: 1.1714 train_acc: 1.0000\n",
      "Epoch 197 train_loss: 1.1734 train_acc: 1.0000\n",
      "Epoch 198 train_loss: 1.1694 train_acc: 1.0000\n",
      "Epoch 199 train_loss: 1.1711 train_acc: 1.0000\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(200):\n",
    "    out = model(data)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    _, pred = torch.max(out[data.train_mask], dim=1)\n",
    "    correct = (pred == data.y[data.train_mask]).sum().item()\n",
    "    acc = correct/data.train_mask.sum().item()\n",
    "\n",
    "    print('Epoch {:03d} train_loss: {:.4f} train_acc: {:.4f}'.format(\n",
    "        epoch, loss.item(), acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 30522\n",
      "After we add 2 tokens\n",
      "vocabulary size: 30524\n",
      "torch.Size([30524, 768])\n",
      "tensor([[-0.0205, -0.0019,  0.0231,  ..., -0.0107, -0.0121,  0.0106],\n",
      "        [ 0.0149, -0.0343,  0.0045,  ..., -0.0124, -0.0097, -0.0394]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "checkpoint = \"/home/btr/bpmn/model/safetensors/bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModel.from_pretrained(checkpoint)\n",
    "\n",
    "print('vocabulary size:', len(tokenizer))\n",
    "num_added_toks = tokenizer.add_tokens(['[ENT_START]', '[ENT_END]'], special_tokens=True)\n",
    "print(\"After we add\", num_added_toks, \"tokens\")\n",
    "print('vocabulary size:', len(tokenizer))\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(model.embeddings.word_embeddings.weight.size())\n",
    "\n",
    "# Randomly generated matrix\n",
    "print(model.embeddings.word_embeddings.weight[-2:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['end', 'of', 'entity']\n",
      "['start', 'of', 'entity']\n",
      "tensor([[-0.0340, -0.0144, -0.0441,  ..., -0.0016,  0.0318, -0.0151],\n",
      "        [-0.0060, -0.0202, -0.0312,  ..., -0.0084,  0.0193, -0.0296]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "descriptions = ['start of entity', 'end of entity']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, token in enumerate(reversed(descriptions), start=1):\n",
    "        tokenized = tokenizer.tokenize(token)\n",
    "        print(tokenized)\n",
    "        tokenized_ids = tokenizer.convert_tokens_to_ids(tokenized)\n",
    "        new_embedding = model.embeddings.word_embeddings.weight[tokenized_ids].mean(axis=0)\n",
    "        model.embeddings.word_embeddings.weight[-i, :] = new_embedding.clone().detach().requires_grad_(True)\n",
    "print(model.embeddings.word_embeddings.weight[-2:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6809, -0.2879, -0.8822,  ..., -0.0319,  0.6351, -0.3029],\n",
      "        [-0.1190, -0.4035, -0.6236,  ..., -0.1687,  0.3868, -0.5921]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model.embeddings.word_embeddings.weight[-2:, :] * 10 + model.embeddings.word_embeddings.weight[-2:, :]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "权重向量: tensor([0.5544, 0.4456], grad_fn=<SoftmaxBackward0>)\n",
      "扩展后的权重向量: tensor([[0.5544, 0.5544, 0.5544],\n",
      "        [0.5544, 0.5544, 0.5544],\n",
      "        [0.5544, 0.5544, 0.5544],\n",
      "        [0.5544, 0.5544, 0.5544],\n",
      "        [0.5544, 0.5544, 0.5544],\n",
      "        [0.5544, 0.5544, 0.5544],\n",
      "        [0.5544, 0.5544, 0.5544],\n",
      "        [0.5544, 0.5544, 0.5544],\n",
      "        [0.5544, 0.5544, 0.5544],\n",
      "        [0.5544, 0.5544, 0.5544]], grad_fn=<ExpandBackward0>)\n",
      "加权求和结果: tensor([[ 2.1220, -0.7132,  0.3025],\n",
      "        [-0.2825,  0.2893,  0.3864],\n",
      "        [ 0.0700,  1.7125, -1.0699],\n",
      "        [ 0.7106,  0.9815, -0.2224],\n",
      "        [-0.1663, -0.2572,  0.0807],\n",
      "        [ 0.4351,  1.0679,  0.3167],\n",
      "        [-0.1876,  0.3540,  0.6517],\n",
      "        [-0.6215, -0.5523,  0.1861],\n",
      "        [ 0.0147,  1.1826,  0.8368],\n",
      "        [ 1.2769,  0.4824,  0.1356]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设我们有两个特征张量，分别是文本嵌入和节点类型嵌入\n",
    "# 假设它们的形状是 [batch_size, feature_size]\n",
    "text_embedding = torch.randn(10, 3)  # 随机生成示例数据\n",
    "node_type_embedding = torch.randn(10, 3)  # 同上\n",
    "\n",
    "# 定义权重向量，权重可以根据需要进行调整\n",
    "# 假设权重是可学习的参数，这里我们随机初始化\n",
    "weights = torch.nn.Parameter(torch.randn(2))\n",
    "\n",
    "# 计算权重的指数，使得权重的和为1（softmax）\n",
    "weights = torch.softmax(weights, dim=0)\n",
    "print(\"权重向量:\", weights)\n",
    "# 将权重扩展到特征张量的形状\n",
    "weights_text = weights[0].expand_as(text_embedding)\n",
    "print(\"扩展后的权重向量:\", weights_text)\n",
    "weights_node_type = weights[1].expand_as(node_type_embedding)\n",
    "\n",
    "# 计算加权求和\n",
    "weighted_sum = (text_embedding * weights_text) + (node_type_embedding * weights_node_type)\n",
    "\n",
    "print(\"加权求和结果:\", weighted_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 1.3854\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 73\u001b[0m\n\u001b[1;32m     71\u001b[0m out \u001b[38;5;241m=\u001b[39m gcn_classifier(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[1;32m     72\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, data\u001b[38;5;241m.\u001b[39my)\n\u001b[0;32m---> 73\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/LLMEnG/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/LLMEnG/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/LLMEnG/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "class FeatureFusionModule(nn.Module):\n",
    "    def __init__(self, text_embedding_dim, node_type_dim, output_dim):\n",
    "        super(FeatureFusionModule, self).__init__()\n",
    "        # 假设文本嵌入和节点类型嵌入的维度分别是text_embedding_dim和node_type_dim\n",
    "        self.fc_text = nn.Linear(text_embedding_dim, output_dim)\n",
    "        self.fc_node_type = nn.Linear(node_type_dim, output_dim)\n",
    "        self.fc_fusion = nn.Linear(output_dim, output_dim)\n",
    "        \n",
    "        # 初始化权重参数\n",
    "        self.weights = nn.Parameter(torch.randn(2))\n",
    "\n",
    "    def forward(self, text_embedding, node_type_embedding):\n",
    "        # 分别对文本嵌入和节点类型嵌入应用全连接层\n",
    "        text_output = self.fc_text(text_embedding)\n",
    "        node_type_output = self.fc_node_type(node_type_embedding)\n",
    "        \n",
    "        # 使用权重对输出进行加权\n",
    "        text_weighted = text_output * self.weights[0]\n",
    "        node_type_weighted = node_type_output * self.weights[1]\n",
    "        \n",
    "        # 将加权结果合并并再次通过全连接层\n",
    "        fused_output = self.fc_fusion(text_weighted + node_type_weighted)\n",
    "        return fused_output\n",
    "\n",
    "class GCNClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCNClassifier, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # 第一层图卷积\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        # 第二层图卷积\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 假设我们有输入数据和目标\n",
    "# 这里我们使用随机数据作为示例\n",
    "num_nodes = 1000\n",
    "num_edges = 2000\n",
    "edge_index = torch.randint(0, num_nodes, (2, num_edges))\n",
    "text_embedding = torch.randn((num_nodes, 16))  # 假设每个节点有16维的文本嵌入\n",
    "node_type_embedding = torch.randn((num_nodes, 8))  # 假设每个节点有8维的节点类型嵌入\n",
    "y = torch.randint(0, 4, (num_nodes,))  # 假设有4个类别\n",
    "\n",
    "# 实例化特征融合模块和GCN分类器\n",
    "feature_fusion = FeatureFusionModule(16, 8, 32)  # 假设输出融合特征维度为32\n",
    "gcn_classifier = GCNClassifier(32, 64, 4)  # 假设GCN的隐藏层维度为64，输出类别数为4\n",
    "\n",
    "# 将特征融合模块的输出作为GCN分类器的输入\n",
    "combined_features = feature_fusion(text_embedding, node_type_embedding)\n",
    "\n",
    "# 将图结构信息和特征信息整合到Data对象中\n",
    "data = Data(x=combined_features, edge_index=edge_index, y=y)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(list(feature_fusion.parameters()) + list(gcn_classifier.parameters()), lr=0.01)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    out = gcn_classifier(data.x, data.edge_index)\n",
    "    loss = criterion(out, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# 训练完成后，feature_fusion.weights 和 gcn_classifier 的参数都学习到了\n",
    "print(\"学习到的特征融合权重:\", feature_fusion.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.3948e-01, -1.2277e-01, -1.0967e-01,  ..., -2.0057e-01,\n",
      "           3.4953e-01,  7.2549e-01],\n",
      "         [ 3.9157e-01,  1.0379e-01, -6.5234e-01,  ..., -5.1784e-04,\n",
      "           7.4655e-01,  4.0899e-01],\n",
      "         [ 7.3401e-01,  3.4777e-01, -3.3854e-03,  ..., -2.0010e-02,\n",
      "          -5.1007e-01, -4.2176e-01],\n",
      "         ...,\n",
      "         [ 6.5899e-01, -3.5357e-01, -2.2464e-01,  ..., -5.1779e-01,\n",
      "          -3.7647e-01,  5.5006e-01],\n",
      "         [ 6.7845e-01,  2.9403e-01, -2.0974e-01,  ...,  2.5586e-01,\n",
      "          -2.7047e-01, -5.8366e-01],\n",
      "         [-1.6920e-02,  1.0900e-01,  1.5850e-01,  ...,  6.9561e-01,\n",
      "          -1.6555e-01, -9.8933e-02]],\n",
      "\n",
      "        [[ 1.5857e-01,  4.8041e-01, -1.7775e-01,  ..., -2.5178e-01,\n",
      "           3.5022e-01,  3.7165e-01],\n",
      "         [ 2.8165e-01,  4.2239e-01, -3.7917e-01,  ..., -1.3355e-02,\n",
      "           8.8876e-01,  4.2816e-01],\n",
      "         [ 4.6219e-01,  6.3719e-01,  3.8362e-01,  ...,  2.5919e-01,\n",
      "           1.8919e-01,  3.1840e-01],\n",
      "         ...,\n",
      "         [ 3.0722e-01,  5.6520e-01,  4.6095e-01,  ...,  1.5050e-01,\n",
      "           1.5375e-02,  1.4220e-01],\n",
      "         [ 2.7022e-01,  4.5986e-01,  4.8362e-01,  ...,  1.6021e-01,\n",
      "          -3.2939e-02,  2.1034e-01],\n",
      "         [ 2.1594e-01,  4.0219e-01,  4.2181e-01,  ...,  1.3091e-01,\n",
      "          -7.9845e-02,  2.5772e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[ 0.1395, -0.1228, -0.1097,  ..., -0.2006,  0.3495,  0.7255],\n",
      "        [ 0.1586,  0.4804, -0.1778,  ..., -0.2518,  0.3502,  0.3716]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([2, 768])\n",
      "tensor([[-0.7919, -0.3541, -0.5460,  ..., -0.3982, -0.5416,  0.8997],\n",
      "        [-0.9194, -0.4750, -0.8049,  ..., -0.3834, -0.7398,  0.9459]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# 定义模型和tokenizer的本地路径\n",
    "local_model_path = \"/home/btr/bpmn/model/safetensors/bert-base-uncased\"\n",
    "\n",
    "# 加载预训练的tokenizer和模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
    "model = AutoModel.from_pretrained(local_model_path)\n",
    "\n",
    "raw_inputs = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "print(outputs.last_hidden_state)  # 输出形状 (batch_size, sequence_length, hidden_size)\n",
    "print(outputs.last_hidden_state[:, 0, :])  # 输出形状 (batch_size, hidden_sizequence_length, hidden_size)\n",
    "print(outputs.last_hidden_state[:, 0, :].shape)  # 输出形状 (batch_size, hidden_size)\n",
    "print(outputs.pooler_output)  # 输出形状 (batch_size, hidden_size)\n",
    "# # 获取嵌入表示\n",
    "# embeddings = []\n",
    "# for text in texts:\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#     # 取最后一层的[CLS] token作为文本的表示\n",
    "#     cls_embedding = outputs.last_hidden_state[:, 0, :]  # (batch_size, hidden_size)\n",
    "#     embeddings.append(cls_embedding)\n",
    "# print(embeddings[0].shape)  # (1, hidden_size)\n",
    "# # 整理为一个Tensor\n",
    "# text_embeddings = torch.cat(embeddings, dim=0)\n",
    "# print(text_embeddings.shape)  # (num_texts, hidden_size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 30522\n",
      "After we add 6 tokens\n",
      "vocabulary size: 30528\n",
      "1 [sign-loop] cyclic signal words\n",
      "2 [sign-parallel] parallel signal words\n",
      "3 [sign-selection] selective signal words\n",
      "4 [sign-successor] sequential signal words\n",
      "5 [condition] gateway conditions\n",
      "6 [activity] activity event entity\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "checkpoint = \"/home/btr/bpmn/model/safetensors/bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModel.from_pretrained(checkpoint)\n",
    "\n",
    "print('vocabulary size:', len(tokenizer))\n",
    "num_added_toks = tokenizer.add_tokens(['[activity]', '[condition]', '[sign-successor]', '[sign-selection]', '[sign-parallel]', '[sign-loop]'], special_tokens=True)\n",
    "print(\"After we add\", num_added_toks, \"tokens\")\n",
    "print('vocabulary size:', len(tokenizer))\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "new_token = {'[activity]': \"activity event entity\",\n",
    "                     '[condition]': \"gateway conditions\",\n",
    "                     '[sign-successor]': \"sequential signal words\",\n",
    "                     '[sign-selection]': \"selective signal words\",\n",
    "                     '[sign-parallel]': \"parallel signal words\",\n",
    "                     '[sign-loop]': \"cyclic signal words\"}\n",
    "with torch.no_grad():\n",
    "    for i, (k, v) in enumerate(reversed(new_token.items()), start=1):\n",
    "        print(i, k, v)\n",
    "        tokenized = tokenizer.tokenize(v)\n",
    "        tokenized_ids = tokenizer.convert_tokens_to_ids(tokenized)\n",
    "        new_token_emb = model.embeddings.word_embeddings.weight[tokenized_ids].mean(dim=0)\n",
    "        model.embeddings.word_embeddings.weight[-i, :] = new_token_emb.clone().detach().requires_grad_(True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(['[activity]', '[condition]'], return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "整体均值: tensor(3.5000)\n",
      "沿着行的均值: tensor([2.5000, 3.5000, 4.5000])\n",
      "沿着列的均值: tensor([2., 5.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个二维张量\n",
    "tensor_2d = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "\n",
    "# 计算整个张量的均值\n",
    "mean_all = torch.mean(tensor_2d)\n",
    "\n",
    "# 沿着特定维度计算均值\n",
    "mean_dim0 = torch.mean(tensor_2d, dim=0)  # 沿着行计算均值\n",
    "mean_dim1 = torch.mean(tensor_2d, dim=1)  # 沿着列计算均值\n",
    "\n",
    "print(\"整体均值:\", mean_all)\n",
    "print(\"沿着行的均值:\", mean_dim0)\n",
    "print(\"沿着列的均值:\", mean_dim1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "checkpoint = \"/home/btr/bpmn/model/safetensors/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModel.from_pretrained(checkpoint)\n",
    "print(model.config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 2, 3])\n",
    "print(a.shape)\n",
    "b = torch.tensor([4, 5, 6])\n",
    "c = [a, b]\n",
    "d = torch.stack(c, dim=0)\n",
    "d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmsage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
