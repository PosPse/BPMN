{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag_2.txt ['1_data1.txt', '2_data1.txt', '3_data1.txt', '4_data1.txt', '5_data1.txt', '6_data1.txt', '7_data1.txt', '8_data1.txt', '9_data1.txt', '10_data1.txt', '11_data1.txt', '12_data1.txt', '13_data1.txt', '14_data1.txt', '15_data1.txt', '16_data1.txt', '17_data1.txt', '18_data1.txt', '19_data1.txt', '20_data1.txt', '21_data1.txt', '22_data1.txt', '23_data1.txt', '24_data1.txt', '25_data1.txt', '26_data1.txt', '27_data1.txt', '28_data1.txt', '29_data1.txt', '30_data1.txt', '32_data1.txt', '34_data1.txt', '35_data1.txt', '36_data1.txt', '37_data1.txt', '38_data1.txt', '39_data1.txt', '40_data1.txt', '41_data1.txt', '42_data1.txt', '43_data1.txt', '44_data1.txt', '45_data1.txt', '46_data1.txt', '47_data1.txt', '48_data1.txt', '49_data1.txt', '50_data1.txt', '51_data1.txt', '52_data1.txt', '53_data1.txt', '54_data1.txt', '55_data1.txt', '56_data1.txt', '57_data1.txt', '58_data1.txt', '59_data1.txt', '60_data1.txt', '61_data1.txt', '62_data1.txt', '63_data1.txt', '64_data1.txt', '65_data1.txt', '66_data1.txt', '67_data1.txt', '68_data1.txt', '69_data1.txt', '71_data1.txt'] 68\n",
      "['1_data1.txt', '2_data1.txt', '3_data1.txt', '4_data1.txt', '5_data1.txt', '6_data1.txt', '7_data1.txt', '8_data1.txt', '9_data1.txt', '10_data1.txt', '11_data1.txt', '12_data1.txt', '13_data1.txt', '14_data1.txt', '15_data1.txt', '16_data1.txt', '17_data1.txt', '18_data1.txt', '19_data1.txt', '20_data1.txt', '21_data1.txt', '22_data1.txt', '23_data1.txt', '24_data1.txt', '25_data1.txt', '26_data1.txt', '27_data1.txt', '28_data1.txt', '29_data1.txt', '30_data1.txt', '32_data1.txt', '34_data1.txt', '35_data1.txt', '36_data1.txt', '37_data1.txt', '38_data1.txt', '39_data1.txt', '40_data1.txt', '41_data1.txt', '42_data1.txt', '43_data1.txt', '44_data1.txt', '45_data1.txt', '46_data1.txt', '47_data1.txt', '48_data1.txt', '49_data1.txt', '50_data1.txt', '51_data1.txt', '52_data1.txt', '53_data1.txt', '54_data1.txt', '55_data1.txt', '56_data1.txt', '57_data1.txt', '58_data1.txt', '59_data1.txt', '60_data1.txt', '61_data1.txt', '62_data1.txt', '63_data1.txt', '64_data1.txt', '65_data1.txt', '66_data1.txt', '67_data1.txt', '68_data1.txt', '69_data1.txt', '71_data1.txt']\n",
      "['110000300001100311010', '110003000111333', '100000000000000100000000000001000000000000111000000000330000000003010000000100000000100000001100000300000100001011133003', '110000000001000100101', '210000000000000000000000000000000110000000000000300000000000001000000000000100000000000100000000001000000000100001000110030003100000100000100000000110301', '1000000100000100001100300101', '210000000000000000000001000000000100000000100000001100000310000100001000110411', '100000000001000000000100000000100000001000000100000100001000100101', '110000003000000110000400001000100113', '100000100001000100113', '210000000000000001000000100000100001000100101', '1000000000100000000100000001000000100000100001000100113', '210000000001000100101', '100000000100000001000000100000100001000100101', '2110000000000400001010130001', '100000000000100000001001000000300100000000100000000100000022100110003000000101', '210000000000000000000001000000000110000000300000001100000100000111003301301101', '100000001000000100000110003000100113', '100000001100000300000100001000100113', '100000110003000100101', '100000000000100000000001000000000100000000100000001000000100000100001000110301', '101100001330000000000300001000100101', '1000000000110000000300000001000000100000110001000100101', '1000000100000100001000101131', '1000000000100000000100000001000000100000100001000100113', '100000000001000000000100000000110000003000000100000111003410410101', '100001000100101', '101000130000110110411', '100000000000000100000000000001100000000000300000000000100000000001000000000100000000100000001000000100000100001000100101', '100000000001110000000440010000400100001100000010000100001000100101', '110003100000101', '100000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000100000000000000000000000000000000000000000001110000000000000000000000000000000000000000331000000000000000000000000000000000000000310000000000000000000000000000000000000001000000000000000000000000000000000000000100000000000000000000000000000000000000100000000000000000000000000000000000001100000000000000000000000000000000000300100000000000000000000000000000000100000000000000000000000000000000001000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000110000000000000000000000000000310000000000000000000000000001000000000000000000000000000100000000000000000000000000100000000000000000000000001000000000000000000000000110010000000000000000000310300000000000000000001030000000000000000000100000000000000000000000000000000000000001000000000000000000110000000000000000310000000000000000000000000000000100000000000000100000000000001000000000000100000000000100000000001000000000110000000310000001000000110000410001000100101', '100000000000000000000000000000100000000000000000000000000001000000000000000000000000000100000000000000000000000000110000000000000000000000000100000000000000000000000001000000000000000000000100000000000000000000001000000000000000000000100000000000000000000101000000000000000001300000000000000000010000000000000000100000000000000001000000000000000100000000000000101000000000001300000000000000000000000100000000001100000000310000000100000001100000410000100001000100101', '100000100001000100101', '110000310001000110411', '1100301101', '100000000100000001000000100000100001100300114', '1000000000110000000300000001000000100000100001100300101', '100000000000000000000000000000000001000000000000000000000000000000000100000000000000000000000000000000100000000000000000000000000000001000000000000000000000000000000100000000000000000000000000000100000000000000000000000000001000000000000000000000000000100000000000000000000000000100000000000000000000000001000000000000000000000000100000000000000000000000100000000000000000000001000000000000000000000100000000000000000000100000000000000000001000000000000000000100000000000000000100000000000000001000000000000000100000000000000100000000000001000000000000100000000000100000000001000000000100000000100000001000000100000100001000100101', '100001110330301', '210000000001000100113', '210000000000000000000001000000000100000000111000003300010300010100001000100101', '100001000100101', '100000000100000001000000110000410001000100101', '111000000000331000000003100000000100000000100000001000000110000300001000100101', '100000100001000101130', '100000100001000100012', '1000000110000100001010100101', '1000000100000100001100100101', '1000000100000100001000110101', '1000100101', '1000000100000100001000100101', '110000001000000111100333103310310101', '1000000000000100000000000100000000001000000000100000000100000001000000110000300001000100110', '100113', '100000000001100000000310000000100000001000000100000100001000100101', '110000000310000001000000100000100001000100101', '100101', '100113', '100001100310101', '1000000110000310001000100101', '3100000100000110003100100113', '310000000100000001100000300000100001000100101', '100000001100000300000110003000100101', '1000100113', '100000000110000003101001000000130030000113300', '100000000000001000000000000100000000000100000000001000000000100000000100000001000000100000100001010130001', '100000000000001010000000000130000000000001000000001000000000100000000100000001000000100000100001000100101']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "filename_list = os.listdir('../data')\n",
    "filename_list = sorted(filename_list, key=lambda x: (len(x), x))\n",
    "tag_2 = filename_list[0]\n",
    "filename_list = filename_list[1:]\n",
    "print(tag_2, filename_list, len(filename_list))\n",
    "rel_list = []\n",
    "with open('../data/' + tag_2, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = list(map(lambda x: x.replace('\\n', ''), lines))\n",
    "    f_list = list(map(lambda x: x.split(' ')[0], lines))\n",
    "    rel_list = list(map(lambda x: x.split(' ')[1], lines))\n",
    "    temp = sorted(zip(f_list, rel_list), key=lambda x: (len(x[0]), x[0]))\n",
    "    f_list, rel_list = zip(*temp)\n",
    "    f_list = list(f_list)\n",
    "    rel_list = list(rel_list)\n",
    "    print(f_list)\n",
    "    print(rel_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = []\n",
    "for filename, rel in zip(filename_list, rel_list):\n",
    "    dataset = {}\n",
    "    with open('../data/' + filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        filename = filename.replace('1.txt', '.txt')\n",
    "        dataset['filename'] = filename\n",
    "        lines = list(map(lambda x: x.replace('\\n', ''), lines))\n",
    "        data = list(map(lambda x: x.split(' ')[0], lines))\n",
    "        label = list(map(lambda x: x.split(' ')[1], lines))\n",
    "        text = ' '.join(data)\n",
    "        dataset['token'] = data\n",
    "        dataset['bio_label'] = label\n",
    "        dataset['text'] = text\n",
    "        dataset['relation'] = rel\n",
    "        dataset_list.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'110000300001100311010'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_list[0]['relation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理存在相邻B-signal、B-condition的情况\n",
    "# 如：B-signal B-signal -> B-signal B-signal\n",
    "for dataset in dataset_list:\n",
    "    bio_label = dataset['bio_label']\n",
    "    modified_bio_label = []\n",
    "    pre_token = None\n",
    "    for token in bio_label:\n",
    "        if token == 'B-signal' and pre_token == 'B-signal':\n",
    "            modified_bio_label.append('I-signal')\n",
    "        elif token == 'B-condition' and pre_token == 'B-condition':\n",
    "            modified_bio_label.append('I-condition')\n",
    "        else:\n",
    "            modified_bio_label.append(token)\n",
    "        pre_token = token\n",
    "    dataset['bio_label'] = modified_bio_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把B-activity、I-activity合并为[activity]\n",
    "# 把B-condition、I-condition合并为[condition]\n",
    "# B-signal、I-signal保留原文中的信号词\n",
    "for dataset in dataset_list:\n",
    "    bio_label = dataset['bio_label']\n",
    "    token = dataset['token']\n",
    "    data_2_mask = []\n",
    "    for word, bio in zip(token, bio_label):\n",
    "        if bio == 'B-activity':\n",
    "            data_2_mask.append('[activity]')\n",
    "        elif bio in ['B-signal', 'I-signal']:\n",
    "            data_2_mask.append(word)\n",
    "        elif bio == 'B-condition':\n",
    "            data_2_mask.append('[condition]')\n",
    "        else:\n",
    "            pass\n",
    "    dataset['data_2_mask'] = data_2_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照信号词在文本中的顺序提取出信号词或信号词组\n",
    "# [['If'], ['If'], ['After'], ['if'], ['but', 'if'], ['After'], ['in', 'both', 'cases']]\n",
    "for dataset in dataset_list:\n",
    "    data_2_mask = dataset['data_2_mask']\n",
    "    signal_token_list = []\n",
    "    current_token_list = []\n",
    "    for token in data_2_mask:\n",
    "        if token not in ['[activity]', '[condition]']:\n",
    "            current_token_list.append(token)\n",
    "        elif current_token_list:\n",
    "            signal_token_list.append(current_token_list)\n",
    "            current_token_list = []\n",
    "    if current_token_list:\n",
    "        signal_token_list.append(current_token_list)\n",
    "    dataset['signal_token_list'] = signal_token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将原有的的data_2_mask序列中的相邻信号词合并，并按先后顺序标号：signal-{count}\n",
    "for dataset in dataset_list:\n",
    "    data_2_mask = dataset['data_2_mask']\n",
    "    data_2_mask_single_signal = []\n",
    "    current_token_list = []\n",
    "    signal_count = 0\n",
    "    for token in data_2_mask:\n",
    "        if token not in ['[activity]', '[condition]']:\n",
    "            current_token_list.append(token)\n",
    "        elif current_token_list:\n",
    "            signal_count += 1 \n",
    "            data_2_mask_single_signal.append(f'signal-{signal_count}')\n",
    "            current_token_list = []\n",
    "            data_2_mask_single_signal.append(token)  \n",
    "        else:\n",
    "            data_2_mask_single_signal.append(token)\n",
    "    dataset['data_2_mask_single_signal'] = data_2_mask_single_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_data.txt ['[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-selection]']\n",
      "2_data.txt ['[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-parallel]', '[sign-selection]']\n",
      "3_data.txt ['[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-selection]']\n",
      "4_data.txt ['[sign-parallel]', '[sign-successor]', '[sign-parallel]']\n",
      "5_data.txt ['[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-loop]', '[sign-selection]', '[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-successor]']\n",
      "6_data.txt ['[sign-successor]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]']\n",
      "7_data.txt ['[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-successor]', '[sign-parallel]', '[sign-successor]']\n",
      "8_data.txt ['[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-successor]', '[sign-successor]', '[sign-successor]']\n",
      "9_data.txt ['[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-parallel]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]']\n",
      "10_data.txt ['[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-selection]']\n",
      "11_data.txt ['[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-successor]', '[sign-successor]']\n",
      "12_data.txt ['[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]']\n",
      "13_data.txt ['[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-successor]']\n",
      "14_data.txt ['[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-successor]']\n",
      "15_data.txt ['[sign-selection]', '[sign-parallel]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-successor]']\n",
      "16_data.txt ['[sign-successor]', '[sign-selection]', '[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-selection]']\n",
      "17_data.txt ['[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-successor]']\n",
      "18_data.txt ['[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]']\n",
      "19_data.txt ['[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]']\n",
      "20_data.txt ['[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-successor]']\n",
      "21_data.txt ['[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-selection]']\n",
      "22_data.txt ['[sign-successor]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]']\n",
      "23_data.txt ['[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-successor]']\n",
      "24_data.txt ['[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-successor]', '[sign-selection]']\n",
      "25_data.txt ['[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-successor]']\n",
      "26_data.txt ['[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-parallel]', '[sign-selection]', '[sign-successor]']\n",
      "27_data.txt ['[sign-successor]']\n",
      "28_data.txt ['[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-parallel]', '[sign-selection]']\n",
      "29_data.txt ['[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-successor]']\n",
      "30_data.txt ['[sign-selection]', '[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-selection]']\n",
      "32_data.txt ['[sign-selection]', '[sign-selection]', '[sign-selection]']\n",
      "34_data.txt ['[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-parallel]', '[sign-successor]', '[sign-successor]']\n",
      "35_data.txt ['[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-parallel]', '[sign-successor]', '[sign-successor]']\n",
      "36_data.txt ['[sign-successor]', '[sign-selection]', '[sign-successor]', '[sign-successor]']\n",
      "37_data.txt ['[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-parallel]', '[sign-successor]']\n",
      "38_data.txt ['[sign-selection]', '[sign-selection]', '[sign-parallel]']\n",
      "39_data.txt ['[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-parallel]']\n",
      "40_data.txt ['[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]']\n",
      "41_data.txt ['[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-successor]']\n",
      "42_data.txt ['[sign-selection]', '[sign-selection]', '[sign-selection]']\n",
      "43_data.txt ['[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]']\n",
      "44_data.txt ['[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]']\n",
      "45_data.txt ['[sign-selection]']\n",
      "46_data.txt ['[sign-successor]', '[sign-successor]', '[sign-parallel]', '[sign-successor]', '[sign-successor]', '[sign-successor]']\n",
      "47_data.txt ['[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-successor]', 'sign-successor', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-successor]']\n",
      "48_data.txt ['[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-selection]']\n",
      "49_data.txt ['[sign-selection]']\n",
      "50_data.txt ['[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-successor]', '[sign-selection]']\n",
      "51_data.txt ['[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]']\n",
      "52_data.txt ['[sign-successor]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-successor]', '[sign-selection]']\n",
      "53_data.txt []\n",
      "54_data.txt ['[sign-successor]']\n",
      "55_data.txt ['[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-successor]']\n",
      "56_data.txt ['[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-successor]']\n",
      "57_data.txt ['[sign-selection]']\n",
      "58_data.txt ['[sign-selection]', '[sign-selection]', '[sign-selection]']\n",
      "59_data.txt ['[sign-selection]']\n",
      "60_data.txt []\n",
      "61_data.txt ['[sign-selection]']\n",
      "62_data.txt ['[sign-selection]']\n",
      "63_data.txt ['[sign-selection]']\n",
      "64_data.txt ['[sign-selection]', '[sign-selection]', '[sign-selection]']\n",
      "65_data.txt ['[sign-selection]', '[sign-selection]', '[sign-selection]']\n",
      "66_data.txt ['[sign-selection]']\n",
      "67_data.txt ['[sign-selection]']\n",
      "68_data.txt ['[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-selection]']\n",
      "69_data.txt ['[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-successor]', '[sign-selection]', '[sign-selection]']\n",
      "71_data.txt ['[sign-selection]', '[sign-successor]', '[sign-selection]', '[sign-selection]', '[sign-selection]', '[sign-successor]', '[sign-parallel]', '[sign-successor]']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = 'http://localhost:11434/api/generate'\n",
    "for dataset in dataset_list:\n",
    "    signal_token_list = dataset['signal_token_list']\n",
    "    signal_token_llm_list = []\n",
    "    for signal_token in signal_token_list:\n",
    "        words = ' '.join(signal_token)\n",
    "        data = {\n",
    "            'model': 'llama3:70b-instruct',\n",
    "            'prompt': f'''\n",
    "            I want to extract activities, and determine the relationship between two activities from a business process text described in natural language. Below I will give you a word or phrase, denoted by [words], which connects two activities, i.e. activity1-[words]-activity2, please judge the type of relationship between two activities based on this words, including 4 types of relationship, as follows:\n",
    "            [sign-selection]: indicates a selection relationship, the most common is to select an activity to be executed under certain conditions.\n",
    "            [sign-successor]: indicates the direct sequential relationship between activities\n",
    "            [sign-parallel]: indicates a concurrent relationship between activities.\n",
    "            [sign-loop]: indicates a circular relationship between activities.\n",
    "            The [words] I gave you are \"[{words}]\", giving the type of relationship(Just answer the type and do not output any extra content).\n",
    "            ''',\n",
    "            'stream': False,\n",
    "        }\n",
    "        try: \n",
    "            response = requests.post(url, json=data)\n",
    "            result = response.json()['response']\n",
    "            signal_token_llm_list.append(result)\n",
    "        except:\n",
    "            dataset_list_json = json.dumps(dataset_list)\n",
    "            with open('datasets2.json', 'w') as f:\n",
    "                f.write(dataset_list_json)\n",
    "    dataset['signal_token_llm_list'] = signal_token_llm_list\n",
    "    print(dataset['filename'], signal_token_llm_list)\n",
    "dataset_list_json = json.dumps(dataset_list)\n",
    "with open('datasets2.json', 'w') as f:\n",
    "    f.write(dataset_list_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_list_json = json.dumps(dataset_list)\n",
    "# with open('datasets.json', 'w') as f:\n",
    "#     f.write(dataset_list_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sign-selection]\n"
     ]
    }
   ],
   "source": [
    "url = 'http://localhost:11434/api/generate'\n",
    "data = {\n",
    "    'model': 'llama3:70b-instruct',\n",
    "    'prompt':  '''\n",
    "            I want to extract activities, and determine the relationship between two activities from a business process text described in natural language. Below I will give you a word or phrase, denoted by [words], which connects two activities, i.e. activity1-[words]-activity2, please judge the type of relationship between two activities based on this words, including 4 types of relationship, as follows:\n",
    "            [sign-selection]: indicates a selection relationship, the most common is to select an activity to be executed under certain conditions.\n",
    "            [sign-successor]: indicates the direct sequential relationship between activities\n",
    "            [sign-parallel]: indicates a concurrent relationship between activities.\n",
    "            [sign-loop]: indicates a circular relationship between activities.\n",
    "            The [words] I gave you are \"in both cases\", giving the type of relationship(Just answer the type and do not output any extra content).\n",
    "        ''',\n",
    "    'stream': False,\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "print(response.json()['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
